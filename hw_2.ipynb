{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (train_test_split, GroupKFold)\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.preprocessing import (OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler)\n",
    "from sklearn.metrics import (classification_report,f1_score, recall_score, precision_score)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основные сведенья после ДЗ1\n",
    "Стало ясно, что целевая переменная (Credit_Score) обладает дисбалансом классов, поэтому будем на это обращать внимание. В качестве безлайна возьмем решающие деревья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>Credit_History_Age_Months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>January</td>\n",
       "      <td>23</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>810.0</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.415295</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>312.5</td>\n",
       "      <td>Good</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>February</td>\n",
       "      <td>23</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1592.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>810.0</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.280222</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>284.8</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>April</td>\n",
       "      <td>23</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1592.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>810.0</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.458074</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>223.5</td>\n",
       "      <td>Good</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>May</td>\n",
       "      <td>23</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>810.0</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>341.5</td>\n",
       "      <td>Good</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>June</td>\n",
       "      <td>23</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1592.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>810.0</td>\n",
       "      <td>27.262259</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>62.430172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.5</td>\n",
       "      <td>Good</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer_ID     Month  Age Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
       "0   CUS_0xd40   January   23  Scientist       19114.12            1824.843333   \n",
       "1   CUS_0xd40  February   23  Scientist       19114.12            1592.843333   \n",
       "2   CUS_0xd40     April   23  Scientist       19114.12            1592.843333   \n",
       "3   CUS_0xd40       May   23  Scientist       19114.12            1824.843333   \n",
       "4   CUS_0xd40      June   23  Scientist       19114.12            1592.843333   \n",
       "\n",
       "   Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  ...  \\\n",
       "0                  3                4              3            4  ...   \n",
       "1                  3                4              3            4  ...   \n",
       "2                  3                4              3            4  ...   \n",
       "3                  3                4              3            4  ...   \n",
       "4                  3                4              3            4  ...   \n",
       "\n",
       "   Credit_Mix  Outstanding_Debt  Credit_Utilization_Ratio  \\\n",
       "0     Unknown             810.0                 26.822620   \n",
       "1        Good             810.0                 31.944960   \n",
       "2        Good             810.0                 31.377862   \n",
       "3        Good             810.0                 24.797347   \n",
       "4        Good             810.0                 27.262259   \n",
       "\n",
       "   Payment_of_Min_Amount Total_EMI_per_month  Amount_invested_monthly  \\\n",
       "0                     No           49.574949                80.415295   \n",
       "1                     No           49.574949               118.280222   \n",
       "2                     No           49.574949               199.458074   \n",
       "3                     No           49.574949                41.420153   \n",
       "4                     No           49.574949                62.430172   \n",
       "\n",
       "                  Payment_Behaviour Monthly_Balance  Credit_Score  \\\n",
       "0   High_spent_Small_value_payments           312.5          Good   \n",
       "1    Low_spent_Large_value_payments           284.8          Good   \n",
       "2    Low_spent_Small_value_payments           223.5          Good   \n",
       "3  High_spent_Medium_value_payments           341.5          Good   \n",
       "4                               NaN           340.5          Good   \n",
       "\n",
       "   Credit_History_Age_Months  \n",
       "0                        265  \n",
       "1                          0  \n",
       "2                        268  \n",
       "3                        269  \n",
       "4                        270  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/prep_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Customer_ID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occupation</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual_Income</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest_Rate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <td>2037</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <td>1906</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Mix</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <td>8518</td>\n",
       "      <td>8.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <td>7377</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Score</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History_Age_Months</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count  percentage\n",
       "Customer_ID                    0        0.00\n",
       "Month                          0        0.00\n",
       "Age                            0        0.00\n",
       "Occupation                     0        0.00\n",
       "Annual_Income                  0        0.00\n",
       "Monthly_Inhand_Salary          0        0.00\n",
       "Num_Bank_Accounts              0        0.00\n",
       "Num_Credit_Card                0        0.00\n",
       "Interest_Rate                  0        0.00\n",
       "Num_of_Loan                    0        0.00\n",
       "Delay_from_due_date            0        0.00\n",
       "Num_of_Delayed_Payment         0        0.00\n",
       "Changed_Credit_Limit        2037        2.10\n",
       "Num_Credit_Inquiries        1906        1.96\n",
       "Credit_Mix                     0        0.00\n",
       "Outstanding_Debt               0        0.00\n",
       "Credit_Utilization_Ratio       0        0.00\n",
       "Payment_of_Min_Amount          0        0.00\n",
       "Total_EMI_per_month            0        0.00\n",
       "Amount_invested_monthly     8518        8.76\n",
       "Payment_Behaviour           7377        7.59\n",
       "Monthly_Balance                0        0.00\n",
       "Credit_Score                   0        0.00\n",
       "Credit_History_Age_Months      0        0.00"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Наличие пустых значений в датасете \n",
    "\n",
    "missing_count = df.isnull().sum()\n",
    "value_count = df.isnull().count()\n",
    "missing_percentage = round(missing_count / value_count * 100, 2)\n",
    "missing_df = pd.DataFrame({\"count\": missing_count, \"percentage\": missing_percentage})\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущенных данных составляет 20.4%\n"
     ]
    }
   ],
   "source": [
    "# посчитаем в процентном соотношение сколько пропущеных данных есть \n",
    "\n",
    "skip_count = df.isna().sum().sum()\n",
    "percent = (skip_count / df.shape[0]) * 100\n",
    "\n",
    "print(f'Пропущенных данных составляет {round(percent,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавимся от пропущенных значений, так как данных после удаления вполне хватит для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit_Score\n",
      "Standard    51724\n",
      "Poor        28205\n",
      "Good        17295\n",
      "Name: count, dtype: int64\n",
      "Размер df до удаления 97224\n",
      "\n",
      "Credit_Score\n",
      "Standard    41970\n",
      "Poor        22734\n",
      "Good        13990\n",
      "Name: count, dtype: int64\n",
      "Размер df после удаления 78694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def data_info(df, word):\n",
    "    print(df['Credit_Score'].value_counts())\n",
    "    print(f'Размер df {word} удаления {df.shape[0]}')\n",
    "    print()\n",
    "\n",
    "data_info(df, 'до')\n",
    "df = df.dropna()\n",
    "data_info(df, 'после')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Делим набор данных на train и test\n",
    "Для сохранения пропорциональности распределения классов целевой переменной будем данные стратифицировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.4, random_state=22, stratify=df['Credit_Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим не нужные признаки Customer_ID и Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['Customer_ID','Month'], inplace=True)\n",
    "df_test.drop(columns=['Customer_ID','Month'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем категориальные признаки в числовые\n",
    "1) Можно обратить внимание, что фичи <code>Credit_Mix</code>, <code>Payment_Behaviour</code> и целевая переменная<code>Credit_Score</code>  \n",
    "обладают неким порядком, поэтому уместно использовать <code>Ordinal Encoding</code>.    \n",
    "2) Для фичи <code>Occupation</code> лучше всего использовать <code>LeaveOneOut</code>, поскольку данная фича  \n",
    "принимает 16 категорий и важно уменьшить утечку информации (кажется, что все encoder-ы типа Ohe не подойдут, так как они просто раздуют df, что для решающего дерева не совсем хороший вариант).\n",
    "3) Для <code>Payment_of_Min_Amount</code> проблемой не будет использовать Ohe (всего классов два)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим числовые и строковые типы данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87674</th>\n",
       "      <td>Journalist</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39369</th>\n",
       "      <td>Entrepreneur</td>\n",
       "      <td>Good</td>\n",
       "      <td>No</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44495</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93773</th>\n",
       "      <td>Teacher</td>\n",
       "      <td>Standard</td>\n",
       "      <td>No</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82131</th>\n",
       "      <td>Architect</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Occupation Credit_Mix Payment_of_Min_Amount  \\\n",
       "87674    Journalist    Unknown                   Yes   \n",
       "39369  Entrepreneur       Good                    No   \n",
       "44495       Unknown   Standard                   Yes   \n",
       "93773       Teacher   Standard                    No   \n",
       "82131     Architect    Unknown                    No   \n",
       "\n",
       "                     Payment_Behaviour Credit_Score  \n",
       "87674   Low_spent_Small_value_payments     Standard  \n",
       "39369  High_spent_Large_value_payments         Good  \n",
       "44495   Low_spent_Small_value_payments     Standard  \n",
       "93773  Low_spent_Medium_value_payments         Poor  \n",
       "82131  High_spent_Large_value_payments     Standard  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digital_column = df_train.select_dtypes([np.number]).columns\n",
    "string_column = df_train.select_dtypes([object]).columns\n",
    "\n",
    "df_train[string_column].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['Credit_Score', 'Credit_Mix','Payment_Behaviour']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Poor','Standard','Good'],\n",
    "                                             ['Unknown','Bad','Standard', 'Good'],\n",
    "                                             ['Unknown',\n",
    "                                              'Low_spent_Small_value_payments',\n",
    "                                              'Low_spent_Medium_value_payments',\n",
    "                                              'Low_spent_Large_value_payments',\n",
    "                                              'High_spent_Small_value_payments',\n",
    "                                              'High_spent_Medium_value_payments',\n",
    "                                              'High_spent_Large_value_payments']  \n",
    "                                            ])\n",
    "\n",
    "leave_one_out_encoder = ce.LeaveOneOutEncoder(cols=['Occupation'])\n",
    "\n",
    "def category_encoder(df_new, topic: str):\n",
    "    \n",
    "    df = df_new.copy()\n",
    "    df['Payment_of_Min_Amount'] = df['Payment_of_Min_Amount'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "    if topic=='train':\n",
    "        df[ordinal_features] = ordinal_encoder.fit_transform(df[ordinal_features])\n",
    "        df['Occupation'] = leave_one_out_encoder.fit_transform(df['Occupation'], df['Credit_Score'])\n",
    "    else:\n",
    "        df[ordinal_features] = ordinal_encoder.transform(df[ordinal_features])\n",
    "        df['Occupation'] = leave_one_out_encoder.transform(df['Occupation'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train_new = category_encoder(df_train, 'train')\n",
    "df_test_new = category_encoder(df_test, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем данные на фичи и целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_x_y(df):\n",
    "    df_new = df.copy()\n",
    "    x_new = df_new.drop(columns=['Credit_Score'], axis=1)\n",
    "    y_new = df_new['Credit_Score']\n",
    "    return x_new, y_new\n",
    "\n",
    "x_train, y_train = select_x_y(df_train_new)\n",
    "x_test, y_test = select_x_y(df_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация константного предсказания\n",
    "Наиболее частотный класс для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      9094\n",
      "         1.0       0.53      1.00      0.70     16788\n",
      "         2.0       0.00      0.00      0.00      5596\n",
      "\n",
      "    accuracy                           0.53     31478\n",
      "   macro avg       0.18      0.33      0.23     31478\n",
      "weighted avg       0.28      0.53      0.37     31478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=22)\n",
    "dummy_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = dummy_clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Безлайн (получим базовое качество)\n",
    "Используем в качетсве безлайна решающие деревья.  \n",
    "Основные премущество:  \n",
    "- не чувствительны к масштабу признаков\n",
    "- менее чуствительны к аномальным значениям\n",
    "\n",
    "Попытаемся невилировать дисбаланс классов с помощью параметра <code>class_weight='balanced'</code>, который автоматически устанавливает веса, обратные частоте классов.   \n",
    "Также рассмотрим подбор устойчивых метрик, которые учитывают дисбаланс классов. В качестве критерия разбивки возьмем \"entropy\", и добавим ограничения в глубину дерева и в количестве объектов в листе.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.72      0.66      9094\n",
      "         1.0       0.79      0.58      0.67     16788\n",
      "         2.0       0.51      0.76      0.61      5596\n",
      "\n",
      "    accuracy                           0.65     31478\n",
      "   macro avg       0.63      0.69      0.65     31478\n",
      "weighted avg       0.69      0.65      0.66     31478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced', \n",
    "    min_samples_leaf=8, \n",
    "    max_depth=6,\n",
    "    random_state=22)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Для poor(0)**: Основной акцент на recall, чтобы модель находила как можно больше клиентов с высоким риском.\n",
    "- **Для standard(1)**: Поддержание баланса между recall и precision, так как клиенты из этой категории считаются промежуточными по риску. (не совсем ясно что подразумевается под стандартом)\n",
    "- **Для good(2)**: Основной акцент на precision, чтобы минимизировать случаи, когда клиент ошибочно классифицируется как poor или standard.\n",
    "\n",
    "\n",
    "### Интерпретация результатов\n",
    "\n",
    "Если модель показывает высокий recall для категории poor, это значит, что она успешно выявляет большинство рискованных клиентов, что важно для управления рисками в кредитном скоринге. Если recall для poor низкий, это может означать о необходимости доработки модели, чтобы сократить пропуски рискованных заемщиков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем использовать ансамбль моделей для получения более высоких результатов\n",
    "Создадим ансамбль моделей с помощью стэкинга. Так как ансамбль будет содержать линейные модели, поэтому стоит предообработать данные:\n",
    "- стандартизировать данные c помощью гибрида <code>StandardScaler</code> и <code>RobustScaler</code>. Думаю, данный гибрид наиболее подходящий выбор для SVM и LogReg, так как эти алгоритмы:\n",
    "    1) Чувствительны к масштабу данных.\n",
    "    2) Наилучшим образом работают с нормально распределёнными признаками.\n",
    "    3) Чувствительны к выбросам.\n",
    "- используем стратегию взвешивания классов, чтобы модель уделяла больше внимания менее представленным классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.75      0.75      9094\n",
      "         1.0       0.80      0.75      0.77     16788\n",
      "         2.0       0.63      0.76      0.69      5596\n",
      "\n",
      "    accuracy                           0.75     31478\n",
      "   macro avg       0.73      0.75      0.74     31478\n",
      "weighted avg       0.76      0.75      0.75     31478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=22, class_weight='balanced')\n",
    "svc = SVC(random_state=22, class_weight='balanced')\n",
    "lr = LogisticRegression(random_state=22, class_weight='balanced')\n",
    "\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    ('robust_scaler', RobustScaler()),\n",
    "    ('standard_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "final_estimator = Pipeline([\n",
    "    ('scaler', preprocessor),\n",
    "    ('lr', LogisticRegression(random_state=22, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "model = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('svc', svc), ('lr', lr)],\n",
    "    final_estimator=final_estimator,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', model)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно увидеть, что ансамбль моделей показал лучший результат по сравнению с бейзлайном."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем оценить бейзлайн через кросс-валидацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для корректной валидации необходимо:\n",
    "\n",
    "- Сгруппировать данные по Customer_ID, чтобы данные одного клиента   \n",
    "не попадали одновременно в train и test.\n",
    "- Учитывать временную компоненту Month, разделяя данные так, чтобы более поздние месяцы   \n",
    "всегда попадали в тестовую выборку.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем все категориальные признаки в числовые. \n",
    "Основные положения:\n",
    "- Впринципе, основная логика сохраняется и дополняется преобразованием  \n",
    "<code>Customer_ID</code> и <code>Month</code>. \n",
    "1) Month преобразуем через Oridinal Encoding,   \n",
    "поскольку переменная содержит перечисление месяцев   \n",
    "(на этапе обучение модели данная фича будет удалена,  \n",
    "так как она нам нужна для сортировки). \n",
    "2) Customer_ID будет преобразована с помощью   \n",
    "LableEncoding, поскольку данная фича будет использоваться для группировки, но не для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# копируем оригинальный df\n",
    "df_new = df.copy()\n",
    "\n",
    "month_order = {\n",
    "    'January': 1, 'February': 2, 'March': 3, 'April': 4, \n",
    "    'May': 5, 'June': 6, 'July': 7, 'August': 8, \n",
    "    'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "}\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "df_new['Month'] = df_new['Month'].map(month_order)\n",
    "df_new['Customer_ID'] = label_encoder.fit_transform(df_new['Customer_ID'])\n",
    "\n",
    "df_new = category_encoder(df_new, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время обучения мы будем удалять фичи Month и Customer_ID, поскольку они нужны будут для сортировки и группировки данных.    \n",
    "При подсчете метрик все значения будут усреднятся с использованием подхода <code>average='weighted'</code>, чтобы учитывать дисбаланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score по каждому фолду: [np.float64(0.6521053027611898), np.float64(0.6592600649182315), np.float64(0.6549332272806824), np.float64(0.6636326981409807), np.float64(0.6647626057263797)]\n",
      "Среднее F1-Score: 0.6589387797654929\n",
      "**************************************************\n",
      "Recall-Score по каждому фолду: [np.float64(0.6490882521125866), np.float64(0.6565855518139653), np.float64(0.6537899485354851), np.float64(0.6632568778194294), np.float64(0.6638073452789427)]\n",
      "Среднее Recall-Score: 0.6573055951120818\n",
      "**************************************************\n",
      "Precision-Score по каждому фолду: [np.float64(0.7113066881873537), np.float64(0.7112626395797526), np.float64(0.7219873308963335), np.float64(0.7179248228462591), np.float64(0.7202102679103896)]\n",
      "Среднее Precision-Score: 0.7165383498840177\n"
     ]
    }
   ],
   "source": [
    "# Сортировка данных по убыванию c начала 1-го месяца года\n",
    "df_new = df_new.sort_values(by=['Month'])\n",
    "\n",
    "X = df_new.drop(columns=['Credit_Score'], axis=1)\n",
    "y = df_new['Credit_Score']\n",
    "groups = df_new['Customer_ID']\n",
    "\n",
    "# важно учитывать, чтобы данные одного клиента попали в одну группу\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X, y, groups=groups)\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced',\n",
    "    min_samples_leaf=8,\n",
    "    max_depth=6,\n",
    "    random_state=22\n",
    ")\n",
    "\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for train_idx, test_idx in splits:\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    " \n",
    "    X_train.drop(columns=['Month', 'Customer_ID'], axis=1)\n",
    "    X_test.drop(columns=['Month', 'Customer_ID'], axis=1)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "\n",
    "print(\"F1-Score по каждому фолду:\", f1_scores)\n",
    "print(\"Среднее F1-Score:\", np.mean(f1_scores))\n",
    "print('*'*50)\n",
    "print(\"Recall-Score по каждому фолду:\", recall_scores)\n",
    "print(\"Среднее Recall-Score:\", np.mean(recall_scores))\n",
    "print('*'*50)\n",
    "print(\"Precision-Score по каждому фолду:\", precision_scores)\n",
    "print(\"Среднее Precision-Score:\", np.mean(precision_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В среднем усреднённые значения метрик будут совпадать с безлайном."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем повысить качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code>Income_Stability</code> = <code>Annual_Income</code>+<code>Monthly_Inhand_Salary </code>\n",
    "\n",
    "\n",
    "Cоздадим новую фичу <code>Income_Stability</code>, которая показывает соотношение годового дохода к ожидаемому годовому доходу на основе ежемесячной зарплаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Income_stability(df: pd.DataFrame):\n",
    "    df['Income_Stability'] = (df['Monthly_Inhand_Salary'] * 12) / df['Annual_Income']\n",
    "    df.drop(columns=['Annual_Income','Monthly_Inhand_Salary'], inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train_new = create_Income_stability(df_train)\n",
    "df_test_new = create_Income_stability(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expense_to_Balance_Ratio = <code>Total_EMI_per_month</code> + <code>Monthly_Balance</code> \n",
    "\n",
    "Эта новая фича будет интерпритировать финансовое состояние клиента,  \n",
    "сколько расходов он имеет по сравнению с его ежемесячным балансом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Expense_to_Balance_Ratio(df: pd.DataFrame):\n",
    "    df['Monthly_Balance'] = df['Monthly_Balance'].apply(lambda x: df['Monthly_Balance'].mean() if x == 0 else x)\n",
    "    df['Expense_to_Balance_Ratio'] = df['Total_EMI_per_month'] / df['Monthly_Balance']\n",
    "\n",
    "    df.drop(columns=['Total_EMI_per_month', 'Monthly_Balance'], inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train_new = create_Expense_to_Balance_Ratio(df_train_new)\n",
    "df_test_new  = create_Expense_to_Balance_Ratio(df_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>Payment_Reliability_Score</code> = <code>Num_of_Delayed_Payment</code> + <code>Payment_of_Min_Amount</code>+<code> Payment_Behaviour</code>+<code>Delay_from_due_date</code>\n",
    "Создадим новую фичу, которая будет интерпритировать общий показатель надежности клиента. Этот показатель будет учитывать количество просрочек, задолжностей по дням, платежное поведение и выполнение минимального платежа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_payment_reliability(df):\n",
    "    score = 100\n",
    "\n",
    "    def payment_behaviour_score(behaviour):\n",
    "        if \"High_spent\" in behaviour:\n",
    "            if \"Small_value\" in behaviour:\n",
    "                return -5\n",
    "            elif \"Medium_value\" in behaviour:\n",
    "                return -10 \n",
    "            elif \"Large_value\" in behaviour:\n",
    "                return -15 \n",
    "        elif \"Low_spent\" in behaviour:\n",
    "            if \"Small_value\" in behaviour:\n",
    "                return 5  \n",
    "            elif \"Medium_value\" in behaviour:\n",
    "                return 0  \n",
    "            elif \"Large_value\" in behaviour:\n",
    "                return -5 \n",
    "        elif \"Unknown\" in behaviour:\n",
    "            return -10  \n",
    "        else:\n",
    "            return 0  \n",
    "\n",
    "    score -= df['Delay_from_due_date'].apply(lambda x: abs(x) * 0.5 if x < 0 else x * 0.5)\n",
    "    score -= df['Num_of_Delayed_Payment'] * 2\n",
    "    score += df['Payment_Behaviour'].apply(payment_behaviour_score) \n",
    "    score -= df['Payment_of_Min_Amount'].apply(lambda x: 5 if x == 'No' else 0)\n",
    "\n",
    "    score = score.clip(0, 100)\n",
    "    return score\n",
    "\n",
    "\n",
    "def prepocessing_score(df):\n",
    "    df_new = df.copy()\n",
    "    df_new['Payment_Reliability_Score'] = calculate_payment_reliability(df_new)\n",
    "    df_new.drop(columns=['Delay_from_due_date', 'Num_of_Delayed_Payment', 'Payment_Behaviour', 'Payment_of_Min_Amount'], inplace=True)\n",
    "    return df_new\n",
    "\n",
    "\n",
    "df_train_new = prepocessing_score(df_train_new)\n",
    "df_test_new = prepocessing_score(df_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим количество числовых и строковых столбцов после FE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество столбцов, содержащее числовые данные 14\n",
      "Количество столбцов, содержащее текстовые данные 3\n"
     ]
    }
   ],
   "source": [
    "digital_column = df_train_new.select_dtypes([np.number]).columns\n",
    "string_column = df_train_new.select_dtypes([object]).columns\n",
    "\n",
    "print(f'Количество столбцов, содержащее числовые данные %s' %len(digital_column))\n",
    "print(f'Количество столбцов, содержащее текстовые данные %s' %len(string_column)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем категориальные признаки в числовые\n",
    "Такое же кодирование как раньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальные значения для:\n",
      "Credit Score: ['Good' 'Standard' 'Poor']\n",
      "Credit_Mix: ['Unknown' 'Good' 'Standard' 'Bad']\n",
      "Occupation: 16\n"
     ]
    }
   ],
   "source": [
    "# посмотрим на все уникальные значения\n",
    "\n",
    "unique_credit_score = df[string_column]['Credit_Score'].unique()\n",
    "unique_credit_mix = df[string_column]['Credit_Mix'].unique()\n",
    "unique_occupation = len(df[string_column]['Occupation'].unique())\n",
    "\n",
    "print(f'Уникальные значения для:\\nCredit Score: {unique_credit_score}\\nCredit_Mix: {unique_credit_mix}\\nOccupation: {unique_occupation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['Credit_Score', 'Credit_Mix']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Poor','Standard','Good'],\n",
    "                                             ['Unknown','Bad','Standard', 'Good']])\n",
    "leave_one_out_encoder = ce.LeaveOneOutEncoder(cols=['Occupation'])\n",
    "\n",
    "def category_encoder(df, topic: str):\n",
    "    if topic=='train':\n",
    "        df[ordinal_features] = ordinal_encoder.fit_transform(df[ordinal_features])\n",
    "        df['Occupation'] = leave_one_out_encoder.fit_transform(df['Occupation'], df['Credit_Score'])\n",
    "    else:\n",
    "        df[ordinal_features] = ordinal_encoder.transform(df[ordinal_features])\n",
    "        df['Occupation'] = leave_one_out_encoder.transform(df['Occupation'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train_new = category_encoder(df_train_new, 'train')\n",
    "df_test_new = category_encoder(df_test_new, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель\n",
    "Посмотрим на качество модели после всех преобразований"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отделим целевую переменную от фичей\n",
    "\n",
    "x_train, y_train = select_x_y(df_train_new)\n",
    "x_test, y_test = select_x_y(df_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для проверки возьмем тот же безлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.67      0.64      9094\n",
      "         1.0       0.77      0.55      0.64     16788\n",
      "         2.0       0.44      0.76      0.56      5596\n",
      "\n",
      "    accuracy                           0.62     31478\n",
      "   macro avg       0.61      0.66      0.61     31478\n",
      "weighted avg       0.67      0.62      0.63     31478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced', \n",
    "    min_samples_leaf=8, \n",
    "    max_depth=6,\n",
    "    random_state=22)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Вывод</code>: FE только ухудшило качество модели. Безлайн с деревьями решений имеет хороший score, но не такой хороший как ансамбль моделей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
