{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (train_test_split, GroupKFold)\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.preprocessing import (OrdinalEncoder, LabelEncoder, StandardScaler, RobustScaler)\n",
    "from sklearn.metrics import (classification_report,f1_score, recall_score, precision_score)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основные сведенья после ДЗ1\n",
    "Стало ясно, что целевая переменная (Credit_Score) обладает дисбалансом классов, поэтому будем на это обращать внимание. В качестве безлайна возьмем решающие деревья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>Credit_History_Age_Months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>January</td>\n",
       "      <td>23</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>810.0</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.415295</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>312.5</td>\n",
       "      <td>Good</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>February</td>\n",
       "      <td>23</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1592.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>810.0</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.280222</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>284.8</td>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>April</td>\n",
       "      <td>23</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1592.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>810.0</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.458074</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>223.5</td>\n",
       "      <td>Good</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>May</td>\n",
       "      <td>23</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>810.0</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>341.5</td>\n",
       "      <td>Good</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>June</td>\n",
       "      <td>23</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1592.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>810.0</td>\n",
       "      <td>27.262259</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>62.430172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.5</td>\n",
       "      <td>Good</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer_ID     Month  Age Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
       "0   CUS_0xd40   January   23  Scientist       19114.12            1824.843333   \n",
       "1   CUS_0xd40  February   23  Scientist       19114.12            1592.843333   \n",
       "2   CUS_0xd40     April   23  Scientist       19114.12            1592.843333   \n",
       "3   CUS_0xd40       May   23  Scientist       19114.12            1824.843333   \n",
       "4   CUS_0xd40      June   23  Scientist       19114.12            1592.843333   \n",
       "\n",
       "   Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  ...  \\\n",
       "0                  3                4              3            4  ...   \n",
       "1                  3                4              3            4  ...   \n",
       "2                  3                4              3            4  ...   \n",
       "3                  3                4              3            4  ...   \n",
       "4                  3                4              3            4  ...   \n",
       "\n",
       "   Credit_Mix  Outstanding_Debt  Credit_Utilization_Ratio  \\\n",
       "0     Unknown             810.0                 26.822620   \n",
       "1        Good             810.0                 31.944960   \n",
       "2        Good             810.0                 31.377862   \n",
       "3        Good             810.0                 24.797347   \n",
       "4        Good             810.0                 27.262259   \n",
       "\n",
       "   Payment_of_Min_Amount Total_EMI_per_month  Amount_invested_monthly  \\\n",
       "0                     No           49.574949                80.415295   \n",
       "1                     No           49.574949               118.280222   \n",
       "2                     No           49.574949               199.458074   \n",
       "3                     No           49.574949                41.420153   \n",
       "4                     No           49.574949                62.430172   \n",
       "\n",
       "                  Payment_Behaviour Monthly_Balance  Credit_Score  \\\n",
       "0   High_spent_Small_value_payments           312.5          Good   \n",
       "1    Low_spent_Large_value_payments           284.8          Good   \n",
       "2    Low_spent_Small_value_payments           223.5          Good   \n",
       "3  High_spent_Medium_value_payments           341.5          Good   \n",
       "4                               NaN           340.5          Good   \n",
       "\n",
       "   Credit_History_Age_Months  \n",
       "0                        265  \n",
       "1                          0  \n",
       "2                        268  \n",
       "3                        269  \n",
       "4                        270  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/prep_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Customer_ID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occupation</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual_Income</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest_Rate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <td>2037</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <td>1906</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Mix</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <td>8518</td>\n",
       "      <td>8.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <td>7377</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_Score</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History_Age_Months</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count  percentage\n",
       "Customer_ID                    0        0.00\n",
       "Month                          0        0.00\n",
       "Age                            0        0.00\n",
       "Occupation                     0        0.00\n",
       "Annual_Income                  0        0.00\n",
       "Monthly_Inhand_Salary          0        0.00\n",
       "Num_Bank_Accounts              0        0.00\n",
       "Num_Credit_Card                0        0.00\n",
       "Interest_Rate                  0        0.00\n",
       "Num_of_Loan                    0        0.00\n",
       "Delay_from_due_date            0        0.00\n",
       "Num_of_Delayed_Payment         0        0.00\n",
       "Changed_Credit_Limit        2037        2.10\n",
       "Num_Credit_Inquiries        1906        1.96\n",
       "Credit_Mix                     0        0.00\n",
       "Outstanding_Debt               0        0.00\n",
       "Credit_Utilization_Ratio       0        0.00\n",
       "Payment_of_Min_Amount          0        0.00\n",
       "Total_EMI_per_month            0        0.00\n",
       "Amount_invested_monthly     8518        8.76\n",
       "Payment_Behaviour           7377        7.59\n",
       "Monthly_Balance                0        0.00\n",
       "Credit_Score                   0        0.00\n",
       "Credit_History_Age_Months      0        0.00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Наличие пустых значений в датасете \n",
    "\n",
    "missing_count = df.isnull().sum()\n",
    "value_count = df.isnull().count()\n",
    "missing_percentage = round(missing_count / value_count * 100, 2)\n",
    "missing_df = pd.DataFrame({\"count\": missing_count, \"percentage\": missing_percentage})\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущенных данных составляет 20.4%\n"
     ]
    }
   ],
   "source": [
    "# посчитаем в процентном соотношение сколько пропущеных данных есть \n",
    "\n",
    "skip_count = df.isna().sum().sum()\n",
    "percent = (skip_count / df.shape[0]) * 100\n",
    "\n",
    "print(f'Пропущенных данных составляет {round(percent,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавимся от пропущенных значений, так как данных после удаления вполне хватит для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit_Score\n",
      "Standard    51724\n",
      "Poor        28205\n",
      "Good        17295\n",
      "Name: count, dtype: int64\n",
      "Размер df до удаления 97224\n",
      "\n",
      "Credit_Score\n",
      "Standard    41970\n",
      "Poor        22734\n",
      "Good        13990\n",
      "Name: count, dtype: int64\n",
      "Размер df после удаления 78694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def data_info(df, word):\n",
    "    print(df['Credit_Score'].value_counts())\n",
    "    print(f'Размер df {word} удаления {df.shape[0]}')\n",
    "    print()\n",
    "\n",
    "data_info(df, 'до')\n",
    "df = df.dropna()\n",
    "data_info(df, 'после')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/prep_data_after_hw_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Делим набор данных на train и test\n",
    "Для сохранения пропорциональности распределения классов целевой переменной будем данные стратифицировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.4, random_state=22, stratify=df['Credit_Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим не нужные признаки Customer_ID и Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['Customer_ID','Month'], inplace=True)\n",
    "df_test.drop(columns=['Customer_ID','Month'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем категориальные признаки в числовые\n",
    "1) Можно обратить внимание, что фичи <code>Credit_Mix</code>, <code>Payment_Behaviour</code> и целевая переменная<code>Credit_Score</code>  \n",
    "обладают неким порядком, поэтому уместно использовать <code>Ordinal Encoding</code>.    \n",
    "2) Для фичи <code>Occupation</code> лучше всего использовать <code>LeaveOneOut</code>, поскольку данная фича  \n",
    "принимает 16 категорий и важно уменьшить утечку информации (кажется, что все encoder-ы типа Ohe не подойдут, так как они просто раздуют df, что для решающего дерева не совсем хороший вариант).\n",
    "3) Для <code>Payment_of_Min_Amount</code> проблемой не будет использовать Ohe (всего классов два)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим числовые и строковые типы данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87674</th>\n",
       "      <td>Journalist</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39369</th>\n",
       "      <td>Entrepreneur</td>\n",
       "      <td>Good</td>\n",
       "      <td>No</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44495</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93773</th>\n",
       "      <td>Teacher</td>\n",
       "      <td>Standard</td>\n",
       "      <td>No</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82131</th>\n",
       "      <td>Architect</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Occupation Credit_Mix Payment_of_Min_Amount  \\\n",
       "87674    Journalist    Unknown                   Yes   \n",
       "39369  Entrepreneur       Good                    No   \n",
       "44495       Unknown   Standard                   Yes   \n",
       "93773       Teacher   Standard                    No   \n",
       "82131     Architect    Unknown                    No   \n",
       "\n",
       "                     Payment_Behaviour Credit_Score  \n",
       "87674   Low_spent_Small_value_payments     Standard  \n",
       "39369  High_spent_Large_value_payments         Good  \n",
       "44495   Low_spent_Small_value_payments     Standard  \n",
       "93773  Low_spent_Medium_value_payments         Poor  \n",
       "82131  High_spent_Large_value_payments     Standard  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digital_column = df_train.select_dtypes([np.number]).columns\n",
    "string_column = df_train.select_dtypes([object]).columns\n",
    "\n",
    "df_train[string_column].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['Credit_Score', 'Credit_Mix','Payment_Behaviour']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Poor','Standard','Good'],\n",
    "                                             ['Unknown','Bad','Standard', 'Good'],\n",
    "                                             ['Unknown',\n",
    "                                              'Low_spent_Small_value_payments',\n",
    "                                              'Low_spent_Medium_value_payments',\n",
    "                                              'Low_spent_Large_value_payments',\n",
    "                                              'High_spent_Small_value_payments',\n",
    "                                              'High_spent_Medium_value_payments',\n",
    "                                              'High_spent_Large_value_payments']  \n",
    "                                            ])\n",
    "\n",
    "leave_one_out_encoder = ce.LeaveOneOutEncoder(cols=['Occupation'])\n",
    "\n",
    "def category_encoder(df_new, topic: str):\n",
    "    \n",
    "    df = df_new.copy()\n",
    "    df['Payment_of_Min_Amount'] = df['Payment_of_Min_Amount'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "    if topic=='train':\n",
    "        df[ordinal_features] = ordinal_encoder.fit_transform(df[ordinal_features])\n",
    "        df['Occupation'] = leave_one_out_encoder.fit_transform(df['Occupation'], df['Credit_Score'])\n",
    "    else:\n",
    "        df[ordinal_features] = ordinal_encoder.transform(df[ordinal_features])\n",
    "        df['Occupation'] = leave_one_out_encoder.transform(df['Occupation'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train_new = category_encoder(df_train, 'train')\n",
    "df_test_new = category_encoder(df_test, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем данные на фичи и целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_x_y(df):\n",
    "    df_new = df.copy()\n",
    "    x_new = df_new.drop(columns=['Credit_Score'], axis=1)\n",
    "    y_new = df_new['Credit_Score']\n",
    "    return x_new, y_new\n",
    "\n",
    "x_train, y_train = select_x_y(df_train_new)\n",
    "x_test, y_test = select_x_y(df_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация константного предсказания\n",
    "Наиболее частотный класс для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      9094\n",
      "         1.0       0.53      1.00      0.70     16788\n",
      "         2.0       0.00      0.00      0.00      5596\n",
      "\n",
      "    accuracy                           0.53     31478\n",
      "   macro avg       0.18      0.33      0.23     31478\n",
      "weighted avg       0.28      0.53      0.37     31478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=22)\n",
    "dummy_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = dummy_clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Безлайн (получим базовое качество)\n",
    "Используем в качетсве безлайна решающие деревья.  \n",
    "Основные премущество:  \n",
    "- не чувствительны к масштабу признаков\n",
    "- менее чуствительны к аномальным значениям\n",
    "\n",
    "Попытаемся невилировать дисбаланс классов с помощью параметра <code>class_weight='balanced'</code>, который автоматически устанавливает веса, обратные частоте классов.   \n",
    "Также рассмотрим подбор устойчивых метрик, которые учитывают дисбаланс классов. В качестве критерия разбивки возьмем \"entropy\", и добавим ограничения в глубину дерева и в количестве объектов в листе.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.72      0.66      9094\n",
      "         1.0       0.79      0.58      0.67     16788\n",
      "         2.0       0.51      0.76      0.61      5596\n",
      "\n",
      "    accuracy                           0.65     31478\n",
      "   macro avg       0.63      0.69      0.65     31478\n",
      "weighted avg       0.69      0.65      0.66     31478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced', \n",
    "    min_samples_leaf=8, \n",
    "    max_depth=6,\n",
    "    random_state=22)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Для poor(0)**: Основной акцент на recall, чтобы модель находила как можно больше клиентов с высоким риском.\n",
    "- **Для standard(1)**: Поддержание баланса между recall и precision, так как клиенты из этой категории считаются промежуточными по риску. (не совсем ясно что подразумевается под стандартом)\n",
    "- **Для good(2)**: Основной акцент на precision, чтобы минимизировать случаи, когда клиент ошибочно классифицируется как poor или standard.\n",
    "\n",
    "\n",
    "### Интерпретация результатов\n",
    "\n",
    "Если модель показывает высокий recall для категории poor, это значит, что она успешно выявляет большинство рискованных клиентов, что важно для управления рисками в кредитном скоринге. Если recall для poor низкий, это может означать о необходимости доработки модели, чтобы сократить пропуски рискованных заемщиков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем использовать ансамбль моделей для получения более высоких результатов\n",
    "Создадим ансамбль моделей с помощью стэкинга. Так как ансамбль будет содержать линейные модели, поэтому стоит предообработать данные:\n",
    "- стандартизировать данные c помощью гибрида <code>StandardScaler</code> и <code>RobustScaler</code>. Думаю, данный гибрид наиболее подходящий выбор для SVM и LogReg, так как эти алгоритмы:\n",
    "    1) Чувствительны к масштабу данных.\n",
    "    2) Наилучшим образом работают с нормально распределёнными признаками.\n",
    "    3) Чувствительны к выбросам.\n",
    "- используем стратегию взвешивания классов, чтобы модель уделяла больше внимания менее представленным классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 27\u001b[0m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m StackingClassifier(\n\u001b[1;32m     18\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m, rf), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvc\u001b[39m\u001b[38;5;124m'\u001b[39m, svc), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, lr)],\n\u001b[1;32m     19\u001b[0m     final_estimator\u001b[38;5;241m=\u001b[39mfinal_estimator,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     23\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[1;32m     24\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstacking\u001b[39m\u001b[38;5;124m'\u001b[39m, model)\n\u001b[1;32m     25\u001b[0m ])\n\u001b[0;32m---> 27\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:672\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    671\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:224\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mappend(estimator)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# Fit the base estimators on the whole training data. Those\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# base estimators will be used in transform, predict, and\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# predict_proba. They are exposed publicly.\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_estimators\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m    231\u001b[0m est_fitted_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/ensemble/_base.py:40\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, fit_params, message_clsname, message)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 40\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/projects/save/delete_2024/ML-base-courses/.venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=22, class_weight='balanced')\n",
    "svc = SVC(random_state=22, class_weight='balanced')\n",
    "lr = LogisticRegression(random_state=22, class_weight='balanced')\n",
    "\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    ('robust_scaler', RobustScaler()),\n",
    "    ('standard_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "final_estimator = Pipeline([\n",
    "    ('scaler', preprocessor),\n",
    "    ('lr', LogisticRegression(random_state=22, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "model = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('svc', svc), ('lr', lr)],\n",
    "    final_estimator=final_estimator,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', model)\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно увидеть, что ансамбль моделей показал лучший результат по сравнению с бейзлайном."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем оценить бейзлайн через кросс-валидацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для корректной валидации необходимо:\n",
    "\n",
    "- Сгруппировать данные по Customer_ID, чтобы данные одного клиента   \n",
    "не попадали одновременно в train и test.\n",
    "- Учитывать временную компоненту Month, разделяя данные так, чтобы более поздние месяцы   \n",
    "всегда попадали в тестовую выборку.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем все категориальные признаки в числовые. \n",
    "Основные положения:\n",
    "- Впринципе, основная логика сохраняется и дополняется преобразованием  \n",
    "<code>Customer_ID</code> и <code>Month</code>. \n",
    "1) Month преобразуем через Oridinal Encoding,   \n",
    "поскольку переменная содержит перечисление месяцев   \n",
    "(на этапе обучение модели данная фича будет удалена,  \n",
    "так как она нам нужна для сортировки). \n",
    "2) Customer_ID будет преобразована с помощью   \n",
    "LableEncoding, поскольку данная фича будет использоваться для группировки, но не для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# копируем оригинальный df\n",
    "df_new = df.copy()\n",
    "\n",
    "month_order = {\n",
    "    'January': 1, 'February': 2, 'March': 3, 'April': 4, \n",
    "    'May': 5, 'June': 6, 'July': 7, 'August': 8, \n",
    "    'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "}\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "df_new['Month'] = df_new['Month'].map(month_order)\n",
    "df_new['Customer_ID'] = label_encoder.fit_transform(df_new['Customer_ID'])\n",
    "\n",
    "df_new = category_encoder(df_new, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время обучения мы будем удалять фичи Month и Customer_ID, поскольку они нужны будут для сортировки и группировки данных.    \n",
    "При подсчете метрик все значения будут усреднятся с использованием подхода <code>average='weighted'</code>, чтобы учитывать дисбаланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score по каждому фолду: [np.float64(0.6521053027611898), np.float64(0.6592600649182315), np.float64(0.6549332272806824), np.float64(0.6636326981409807), np.float64(0.6647626057263797)]\n",
      "Среднее F1-Score: 0.6589387797654929\n",
      "**************************************************\n",
      "Recall-Score по каждому фолду: [np.float64(0.6490882521125866), np.float64(0.6565855518139653), np.float64(0.6537899485354851), np.float64(0.6632568778194294), np.float64(0.6638073452789427)]\n",
      "Среднее Recall-Score: 0.6573055951120818\n",
      "**************************************************\n",
      "Precision-Score по каждому фолду: [np.float64(0.7113066881873537), np.float64(0.7112626395797526), np.float64(0.7219873308963335), np.float64(0.7179248228462591), np.float64(0.7202102679103896)]\n",
      "Среднее Precision-Score: 0.7165383498840177\n"
     ]
    }
   ],
   "source": [
    "# Сортировка данных по убыванию c начала 1-го месяца года\n",
    "df_new = df_new.sort_values(by=['Month'])\n",
    "\n",
    "X = df_new.drop(columns=['Credit_Score'], axis=1)\n",
    "y = df_new['Credit_Score']\n",
    "groups = df_new['Customer_ID']\n",
    "\n",
    "# важно учитывать, чтобы данные одного клиента попали в одну группу\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X, y, groups=groups)\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced',\n",
    "    min_samples_leaf=8,\n",
    "    max_depth=6,\n",
    "    random_state=22\n",
    ")\n",
    "\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for train_idx, test_idx in splits:\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    " \n",
    "    X_train.drop(columns=['Month', 'Customer_ID'], axis=1)\n",
    "    X_test.drop(columns=['Month', 'Customer_ID'], axis=1)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "\n",
    "print(\"F1-Score по каждому фолду:\", f1_scores)\n",
    "print(\"Среднее F1-Score:\", np.mean(f1_scores))\n",
    "print('*'*50)\n",
    "print(\"Recall-Score по каждому фолду:\", recall_scores)\n",
    "print(\"Среднее Recall-Score:\", np.mean(recall_scores))\n",
    "print('*'*50)\n",
    "print(\"Precision-Score по каждому фолду:\", precision_scores)\n",
    "print(\"Среднее Precision-Score:\", np.mean(precision_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В среднем усреднённые значения метрик будут совпадать с безлайном."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем повысить качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code>Income_Stability</code> = <code>Annual_Income</code>+<code>Monthly_Inhand_Salary </code>\n",
    "\n",
    "\n",
    "Cоздадим новую фичу <code>Income_Stability</code>, которая показывает соотношение годового дохода к ожидаемому годовому доходу на основе ежемесячной зарплаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Income_stability(df: pd.DataFrame):\n",
    "    df['Income_Stability'] = (df['Monthly_Inhand_Salary'] * 12) / df['Annual_Income']\n",
    "    df.drop(columns=['Annual_Income','Monthly_Inhand_Salary'], inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train_new = create_Income_stability(df_train)\n",
    "df_test_new = create_Income_stability(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expense_to_Balance_Ratio = <code>Total_EMI_per_month</code> + <code>Monthly_Balance</code> \n",
    "\n",
    "Эта новая фича будет интерпритировать финансовое состояние клиента,  \n",
    "сколько расходов он имеет по сравнению с его ежемесячным балансом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Expense_to_Balance_Ratio(df: pd.DataFrame):\n",
    "    df['Monthly_Balance'] = df['Monthly_Balance'].apply(lambda x: df['Monthly_Balance'].mean() if x == 0 else x)\n",
    "    df['Expense_to_Balance_Ratio'] = df['Total_EMI_per_month'] / df['Monthly_Balance']\n",
    "\n",
    "    df.drop(columns=['Total_EMI_per_month', 'Monthly_Balance'], inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train_new = create_Expense_to_Balance_Ratio(df_train_new)\n",
    "df_test_new  = create_Expense_to_Balance_Ratio(df_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>Payment_Reliability_Score</code> = <code>Num_of_Delayed_Payment</code> + <code>Payment_of_Min_Amount</code>+<code> Payment_Behaviour</code>+<code>Delay_from_due_date</code>\n",
    "Создадим новую фичу, которая будет интерпритировать общий показатель надежности клиента. Этот показатель будет учитывать количество просрочек, задолжностей по дням, платежное поведение и выполнение минимального платежа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_payment_reliability(df):\n",
    "    score = 100\n",
    "\n",
    "    def payment_behaviour_score(behaviour):\n",
    "        if \"High_spent\" in behaviour:\n",
    "            if \"Small_value\" in behaviour:\n",
    "                return -5\n",
    "            elif \"Medium_value\" in behaviour:\n",
    "                return -10 \n",
    "            elif \"Large_value\" in behaviour:\n",
    "                return -15 \n",
    "        elif \"Low_spent\" in behaviour:\n",
    "            if \"Small_value\" in behaviour:\n",
    "                return 5  \n",
    "            elif \"Medium_value\" in behaviour:\n",
    "                return 0  \n",
    "            elif \"Large_value\" in behaviour:\n",
    "                return -5 \n",
    "        elif \"Unknown\" in behaviour:\n",
    "            return -10  \n",
    "        else:\n",
    "            return 0  \n",
    "\n",
    "    score -= df['Delay_from_due_date'].apply(lambda x: abs(x) * 0.5 if x < 0 else x * 0.5)\n",
    "    score -= df['Num_of_Delayed_Payment'] * 2\n",
    "    score += df['Payment_Behaviour'].apply(payment_behaviour_score) \n",
    "    score -= df['Payment_of_Min_Amount'].apply(lambda x: 5 if x == 'No' else 0)\n",
    "\n",
    "    score = score.clip(0, 100)\n",
    "    return score\n",
    "\n",
    "\n",
    "def prepocessing_score(df):\n",
    "    df_new = df.copy()\n",
    "    df_new['Payment_Reliability_Score'] = calculate_payment_reliability(df_new)\n",
    "    df_new.drop(columns=['Delay_from_due_date', 'Num_of_Delayed_Payment', 'Payment_Behaviour', 'Payment_of_Min_Amount'], inplace=True)\n",
    "    return df_new\n",
    "\n",
    "\n",
    "df_train_new = prepocessing_score(df_train_new)\n",
    "df_test_new = prepocessing_score(df_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим количество числовых и строковых столбцов после FE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество столбцов, содержащее числовые данные 14\n",
      "Количество столбцов, содержащее текстовые данные 3\n"
     ]
    }
   ],
   "source": [
    "digital_column = df_train_new.select_dtypes([np.number]).columns\n",
    "string_column = df_train_new.select_dtypes([object]).columns\n",
    "\n",
    "print(f'Количество столбцов, содержащее числовые данные %s' %len(digital_column))\n",
    "print(f'Количество столбцов, содержащее текстовые данные %s' %len(string_column)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем категориальные признаки в числовые\n",
    "Такое же кодирование как раньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальные значения для:\n",
      "Credit Score: ['Good' 'Standard' 'Poor']\n",
      "Credit_Mix: ['Unknown' 'Good' 'Standard' 'Bad']\n",
      "Occupation: 16\n"
     ]
    }
   ],
   "source": [
    "# посмотрим на все уникальные значения\n",
    "\n",
    "unique_credit_score = df[string_column]['Credit_Score'].unique()\n",
    "unique_credit_mix = df[string_column]['Credit_Mix'].unique()\n",
    "unique_occupation = len(df[string_column]['Occupation'].unique())\n",
    "\n",
    "print(f'Уникальные значения для:\\nCredit Score: {unique_credit_score}\\nCredit_Mix: {unique_credit_mix}\\nOccupation: {unique_occupation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['Credit_Score', 'Credit_Mix']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Poor','Standard','Good'],\n",
    "                                             ['Unknown','Bad','Standard', 'Good']])\n",
    "leave_one_out_encoder = ce.LeaveOneOutEncoder(cols=['Occupation'])\n",
    "\n",
    "def category_encoder(df, topic: str):\n",
    "    if topic=='train':\n",
    "        df[ordinal_features] = ordinal_encoder.fit_transform(df[ordinal_features])\n",
    "        df['Occupation'] = leave_one_out_encoder.fit_transform(df['Occupation'], df['Credit_Score'])\n",
    "    else:\n",
    "        df[ordinal_features] = ordinal_encoder.transform(df[ordinal_features])\n",
    "        df['Occupation'] = leave_one_out_encoder.transform(df['Occupation'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train_new = category_encoder(df_train_new, 'train')\n",
    "df_test_new = category_encoder(df_test_new, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель\n",
    "Посмотрим на качество модели после всех преобразований"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отделим целевую переменную от фичей\n",
    "\n",
    "x_train, y_train = select_x_y(df_train_new)\n",
    "x_test, y_test = select_x_y(df_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для проверки возьмем тот же безлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.67      0.64      9094\n",
      "         1.0       0.77      0.55      0.64     16788\n",
      "         2.0       0.44      0.76      0.56      5596\n",
      "\n",
      "    accuracy                           0.62     31478\n",
      "   macro avg       0.61      0.66      0.61     31478\n",
      "weighted avg       0.67      0.62      0.63     31478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    class_weight='balanced', \n",
    "    min_samples_leaf=8, \n",
    "    max_depth=6,\n",
    "    random_state=22)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Вывод</code>: FE только ухудшило качество модели. Безлайн с деревьями решений имеет хороший score, но не такой хороший как ансамбль моделей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
